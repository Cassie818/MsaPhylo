{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Deciphering the Black Box: Mastering the MSA Transformer for Phylogenetic Tree Construction"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "159965dd8885eca0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Install and import package ##"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ff6b7b4fa8508565"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-09-23T01:21:29.648451Z",
     "start_time": "2023-09-23T01:21:20.587042Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Bio in /Users/cassie/opt/anaconda3/envs/deeplearning/lib/python3.8/site-packages (1.5.9)\r\n",
      "Requirement already satisfied: mygene in /Users/cassie/opt/anaconda3/envs/deeplearning/lib/python3.8/site-packages (from Bio) (3.2.2)\r\n",
      "Requirement already satisfied: gprofiler-official in /Users/cassie/opt/anaconda3/envs/deeplearning/lib/python3.8/site-packages (from Bio) (1.0.0)\r\n",
      "Requirement already satisfied: pooch in /Users/cassie/opt/anaconda3/envs/deeplearning/lib/python3.8/site-packages (from Bio) (1.7.0)\r\n",
      "Requirement already satisfied: requests in /Users/cassie/opt/anaconda3/envs/deeplearning/lib/python3.8/site-packages (from Bio) (2.28.1)\r\n",
      "Requirement already satisfied: tqdm in /Users/cassie/opt/anaconda3/envs/deeplearning/lib/python3.8/site-packages (from Bio) (4.65.0)\r\n",
      "Requirement already satisfied: pandas in /Users/cassie/opt/anaconda3/envs/deeplearning/lib/python3.8/site-packages (from Bio) (1.5.2)\r\n",
      "Requirement already satisfied: biopython>=1.80 in /Users/cassie/opt/anaconda3/envs/deeplearning/lib/python3.8/site-packages (from Bio) (1.81)\r\n",
      "Requirement already satisfied: numpy in /Users/cassie/opt/anaconda3/envs/deeplearning/lib/python3.8/site-packages (from biopython>=1.80->Bio) (1.23.5)\r\n",
      "Requirement already satisfied: biothings-client>=0.2.6 in /Users/cassie/opt/anaconda3/envs/deeplearning/lib/python3.8/site-packages (from mygene->Bio) (0.3.0)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Users/cassie/opt/anaconda3/envs/deeplearning/lib/python3.8/site-packages (from pandas->Bio) (2.8.2)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/cassie/opt/anaconda3/envs/deeplearning/lib/python3.8/site-packages (from pandas->Bio) (2022.7)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/cassie/opt/anaconda3/envs/deeplearning/lib/python3.8/site-packages (from pooch->Bio) (22.0)\r\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /Users/cassie/opt/anaconda3/envs/deeplearning/lib/python3.8/site-packages (from pooch->Bio) (2.5.2)\r\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/cassie/opt/anaconda3/envs/deeplearning/lib/python3.8/site-packages (from requests->Bio) (2.0.4)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/cassie/opt/anaconda3/envs/deeplearning/lib/python3.8/site-packages (from requests->Bio) (3.4)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/cassie/opt/anaconda3/envs/deeplearning/lib/python3.8/site-packages (from requests->Bio) (1.26.14)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/cassie/opt/anaconda3/envs/deeplearning/lib/python3.8/site-packages (from requests->Bio) (2023.5.7)\r\n",
      "Requirement already satisfied: six>=1.5 in /Users/cassie/opt/anaconda3/envs/deeplearning/lib/python3.8/site-packages (from python-dateutil>=2.8.1->pandas->Bio) (1.16.0)\r\n",
      "Requirement already satisfied: ete3 in /Users/cassie/opt/anaconda3/envs/deeplearning/lib/python3.8/site-packages (3.1.2)\r\n",
      "Collecting dendropy\r\n",
      "  Using cached DendroPy-4.6.1-py3-none-any.whl (458 kB)\r\n",
      "Requirement already satisfied: setuptools in /Users/cassie/opt/anaconda3/envs/deeplearning/lib/python3.8/site-packages (from dendropy) (65.6.3)\r\n",
      "Installing collected packages: dendropy\r\n",
      "Successfully installed dendropy-4.6.1\r\n"
     ]
    }
   ],
   "source": [
    "!pip install fair-esm --quiet\n",
    "!pip install transformers --quiet\n",
    "!pip install pysam --quiet\n",
    "!pip install Bio\n",
    "!pip install ete3\n",
    "!pip install dendropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import random\n",
    "import string\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "from Bio import SeqIO\n",
    "from ete3 import Tree\n",
    "from esm import Alphabet, FastaBatchedDataset, ProteinBertModel, MSATransformer, pretrained\n",
    "from pysam import FastaFile, FastxFile\n",
    "from scipy import stats\n",
    "from torch.utils.data import TensorDataset, Dataset"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-23T01:21:33.690095Z",
     "start_time": "2023-09-23T01:21:33.676039Z"
    }
   },
   "id": "f1abb88b67515501"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Generate 4 kinds of MSA ##"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "507509b4bad5f3c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class ChangeAA:\n",
    "\n",
    "  def __init__(self, protein_family):\n",
    "    self.protein_family = protein_family\n",
    "    self.msa_file = '/content/drive/MyDrive/PhD/Pfam/'+ f\"{self.pfam}_seed_hmmalign_no_inserts.fasta\"\n",
    "\n",
    "  def shuffle_col(self,column):\n",
    "\n",
    "    if len(set(column)) == 1:\n",
    "        return column\n",
    "\n",
    "    aa_list = list(column)\n",
    "    random.shuffle(aa_list)\n",
    "\n",
    "    return ''.join(aa_list)\n",
    "\n",
    "  def mix_fasta_column(self):\n",
    "    mix_column = '/content/drive/MyDrive/PhD/Pfam/' + f\"{self.pfam}_mix_column.fasta\"\n",
    "\n",
    "    records = list(SeqIO.parse(self.msa_file, \"fasta\"))\n",
    "    seq_length = len(records[0].seq)\n",
    "    shuffled_records = []\n",
    "\n",
    "    for i in range(seq_length):\n",
    "        column = ''.join(record.seq[i] for record in records)\n",
    "        shuffled_column = self.shuffle_col(column)\n",
    "        for j, record in enumerate(records):\n",
    "            if j >= len(shuffled_records):\n",
    "                shuffled_records.append(record)\n",
    "            shuffled_records[j].seq = shuffled_records[j].seq[:i] + shuffled_column[j] + shuffled_records[j].seq[i+1:]\n",
    "\n",
    "    shuffled_msa = [record for record in shuffled_records]\n",
    "    SeqIO.write(shuffled_msa, mix_column, \"fasta\")\n",
    "\n",
    "    print('Generate Mix columns data!')\n",
    "\n",
    "  def shuffle_fasta_all(self):\n",
    "    shuffle_all = '/content/drive/MyDrive/PhD/Pfam/' + f\"{self.pfam}_shuffle_all.fasta\"\n",
    "    shuffle_order = '/content/drive/MyDrive/PhD/Pfam/' + f\"{self.pfam}_shuffle_all_order.txt\"\n",
    "\n",
    "    with open(self.msa_file, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    sequences = []\n",
    "    current_sequence = ''\n",
    "    for line in lines:\n",
    "        line = line.rstrip()\n",
    "        if line.startswith('>'):\n",
    "            if current_sequence:\n",
    "                sequences.append(current_sequence)\n",
    "            sequences.append(line)\n",
    "            current_sequence = ''\n",
    "        else:\n",
    "            current_sequence += line\n",
    "    sequences.append(current_sequence)\n",
    "    sequence_length = len(sequences[1])\n",
    "\n",
    "    shuffled_sequences = []\n",
    "    shuffled_order = []\n",
    "\n",
    "    for sequence in sequences:\n",
    "        if not sequence.startswith('>'):\n",
    "            # for each sequence, regenerate new sequences in a random order using the same amino acid composition\n",
    "            shuffled_indices = random.sample(range(len(sequence)), len(sequence))\n",
    "            shuffled_order.append(shuffled_indices)\n",
    "            shuffled_sequence = ''.join(''.join([sequence[i] for i in shuffled_indices]))\n",
    "            shuffled_sequences.append(shuffled_sequence)\n",
    "        else:\n",
    "            shuffled_sequences.append(sequence)\n",
    "\n",
    "    with open(shuffle_all, 'w') as file:\n",
    "        file.write('\\n'.join(shuffled_sequences))\n",
    "\n",
    "    with open(shuffle_order,'w') as file:\n",
    "      write = csv.writer(file)\n",
    "      write.writerows(shuffled_order)\n",
    "\n",
    "    print('Generate Shuffle all data!')\n",
    "\n",
    "\n",
    "  def shuffle_fasta_column(self):\n",
    "    shuffle_column = '/content/drive/MyDrive/PhD/Pfam/' + f\"{self.pfam}_shuffle_column.fasta\"\n",
    "    shuffle_order = '/content/drive/MyDrive/PhD/Pfam/' + f\"{self.pfam}_shuffle_column_order.txt\"\n",
    "\n",
    "    with open(self.msa_file, 'r') as file:\n",
    "      lines = file.readlines()\n",
    "\n",
    "    sequences = []\n",
    "    current_sequence = ''\n",
    "    for line in lines:\n",
    "      line = line.rstrip()\n",
    "      if line.startswith('>'):\n",
    "        if current_sequence:\n",
    "          sequences.append(current_sequence)\n",
    "        sequences.append(line)\n",
    "        current_sequence = ''\n",
    "      else:\n",
    "        current_sequence += line\n",
    "    sequences.append(current_sequence)\n",
    "    sequence_length = len(sequences[1])\n",
    "\n",
    "    shuffled_sequences = []\n",
    "    shuffled_order = []\n",
    "    # regenernate new sequences using the same order\n",
    "    shuffled_indices = random.sample(range(sequence_length), sequence_length)\n",
    "    shuffled_order.append(shuffled_indices)\n",
    "\n",
    "    for sequence in sequences:\n",
    "      if not sequence.startswith('>'):\n",
    "        shuffled_sequence = ''.join(''.join([sequence[i] for i in shuffled_indices]))\n",
    "        shuffled_sequences.append(shuffled_sequence)\n",
    "      else:\n",
    "        shuffled_sequences.append(sequence)\n",
    "\n",
    "    with open(shuffle_column, 'w') as file:\n",
    "      file.write('\\n'.join(shuffled_sequences))\n",
    "\n",
    "    with open(shuffle_order,'w') as file:\n",
    "      write = csv.writer(file)\n",
    "      write.writerows(shuffled_order)\n",
    "\n",
    "    print('Generate Shuffle columns data!')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "59c6d25b8e8cb90d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Generate four kinds of embeddings and attentions"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8043fea857aab504"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def remove_insertions(sequence):\n",
    "  deletekeys = dict.fromkeys(string.ascii_lowercase)\n",
    "  deletekeys[\".\"] = None\n",
    "  deletekeys[\"*\"] = None\n",
    "  translation = str.maketrans(deletekeys)\n",
    "  \"\"\" Removes any insertions into the sequence. Needed to load aligned sequences in an MSA. \"\"\"\n",
    "  return sequence.translate(translation)\n",
    "\n",
    "class Extractor:\n",
    "    EMB_PATH = './embeddings/'\n",
    "    ATTN_PATH = './attentions/'\n",
    "    MSA_PATH = './MSA/'\n",
    "\n",
    "    MSA_TYPE_MAP = {\n",
    "        \"no\": \"_seed_hmmalign_no_inserts.fasta\",\n",
    "        \"sc\": \"_shuffle_column.fasta\",\n",
    "        \"sa\": \"_shuffle_all.fasta\",\n",
    "        \"default\": \"_mix_column.fasta\"\n",
    "    }\n",
    "\n",
    "    EMB_TYPE_MAP = {\n",
    "        \"no\": \"_emb_no_shuffle_\",\n",
    "        \"sc\": \"_emb_shuffle_column_\",\n",
    "        \"sa\": \"_emb_shuffle_all_\",\n",
    "        \"default\": \"_emb_mix_column_\"\n",
    "    }\n",
    "    \n",
    "    ATTN_TYPE_MAP = {\n",
    "        \"no\": \"_attn_no_shuffle_\",\n",
    "        \"sc\": \"_attn_shuffle_column_\",\n",
    "        \"sa\": \"_attn_shuffle_all_\",\n",
    "        \"default\": \"_attn_mix_column_\"\n",
    "    }\n",
    "\n",
    "    def __init__(self, protein_family, msa_type):\n",
    "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        self.model_name = \"esm_msa1b_t12_100M_UR50S\"\n",
    "        self.encoding_dim, self.encoding_layer, self.max_seq_length = 768, 12, 1022\n",
    "        self.protein_family = protein_family\n",
    "        self.msa_type = msa_type if msa_type in self.MSA_TYPE_MAP else \"default\"\n",
    "        self.msa_fasta_file = f'{self.MSA_PATH}{protein_family}{self.MSA_TYPE_MAP[self.msa_type]}'\n",
    "\n",
    "    def read_msa(self):\n",
    "        return [(record.description, remove_insertions(str(record.seq)))\n",
    "                for record in SeqIO.parse(self.msa_fasta_file, \"fasta\")]\n",
    "\n",
    "    def get_embedding(self):\n",
    "        model, alphabet = pretrained.load_model_and_alphabet(self.model_name)\n",
    "        batch_converter = alphabet.get_batch_converter()\n",
    "\n",
    "        embedding = f'{self.EMB_PATH}{self.protein_family}{self.EMB_TYPE_MAP[self.msa_type]}{self.model_name}.pt'\n",
    "\n",
    "        model.eval()\n",
    "        msa_data = [self.read_msa()]\n",
    "        msa_labels, msa_strs, msa_tokens = batch_converter(msa_data)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            results = model(msa_tokens, repr_layers=[12], need_head_weights=False)\n",
    "\n",
    "        torch.save(results,embedding)\n",
    "        print(\"Embeddings saved in output file:\",embedding)\n",
    "    \n",
    "    def get_col_attention(self):\n",
    "        model, alphabet = pretrained.load_model_and_alphabet(self.model_name)\n",
    "        batch_converter = alphabet.get_batch_converter()\n",
    "\n",
    "        attn = f'{self.ATTN_PATH}{self.protein_family}{self.ATTN_TYPE_MAP[self.msa_type]}{self.model_name}.pt'\n",
    "\n",
    "        model.eval()\n",
    "        msa_data = [self.read_msa()]\n",
    "        msa_labels, msa_strs, msa_tokens = batch_converter(msa_data)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            results = model(msa_tokens, repr_layers=[12], need_head_weights=True)\n",
    "\n",
    "        torch.save(results, attn)\n",
    "        print(\"Column attention saved in output file:\", attn)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f032996cc3252c6f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
