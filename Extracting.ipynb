{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Deciphering the Black Box: Mastering the MSA Transformer for Phylogenetic Tree Construction"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "159965dd8885eca0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.Install and import package ##"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ff6b7b4fa8508565"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-09-22T05:23:40.022087Z",
     "start_time": "2023-09-22T05:23:29.847029Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Bio in /opt/anaconda3/envs/tf37/lib/python3.7/site-packages (1.4.0)\r\n",
      "Requirement already satisfied: mygene in /opt/anaconda3/envs/tf37/lib/python3.7/site-packages (from Bio) (3.2.2)\r\n",
      "Requirement already satisfied: biopython>=1.79 in /opt/anaconda3/envs/tf37/lib/python3.7/site-packages (from Bio) (1.79)\r\n",
      "Requirement already satisfied: requests in /opt/anaconda3/envs/tf37/lib/python3.7/site-packages (from Bio) (2.28.0)\r\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/envs/tf37/lib/python3.7/site-packages (from Bio) (4.64.1)\r\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/envs/tf37/lib/python3.7/site-packages (from biopython>=1.79->Bio) (1.21.5)\r\n",
      "Requirement already satisfied: biothings-client>=0.2.6 in /opt/anaconda3/envs/tf37/lib/python3.7/site-packages (from mygene->Bio) (0.2.6)\r\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/anaconda3/envs/tf37/lib/python3.7/site-packages (from requests->Bio) (2.0.4)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/anaconda3/envs/tf37/lib/python3.7/site-packages (from requests->Bio) (1.26.9)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/envs/tf37/lib/python3.7/site-packages (from requests->Bio) (2022.12.7)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/envs/tf37/lib/python3.7/site-packages (from requests->Bio) (3.3)\r\n",
      "Requirement already satisfied: ete3 in /opt/anaconda3/envs/tf37/lib/python3.7/site-packages (3.1.3)\r\n",
      "Requirement already satisfied: dendropy in /opt/anaconda3/envs/tf37/lib/python3.7/site-packages (4.6.1)\r\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/envs/tf37/lib/python3.7/site-packages (from dendropy) (61.2.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install fair-esm --quiet\n",
    "!pip install transformers --quiet\n",
    "!pip install pysam --quiet\n",
    "!pip install Bio\n",
    "!pip install ete3\n",
    "!pip install dendropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import torch\n",
    "import string\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import esm\n",
    "from esm import Alphabet, FastaBatchedDataset, ProteinBertModel, pretrained, MSATransformer\n",
    "from pysam import FastaFile,FastxFile\n",
    "from torch.utils.data import TensorDataset,Dataset\n",
    "import pandas as pd\n",
    "from Bio import SeqIO\n",
    "from ete3 import Tree\n",
    "from scipy import stats\n",
    "import csv\n",
    "import sys\n",
    "import os\n",
    "import torch.utils.data as data\n",
    "import random"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-22T06:56:49.098496Z",
     "start_time": "2023-09-22T06:56:38.127096Z"
    }
   },
   "id": "f1abb88b67515501"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class ChangeAA:\n",
    "\n",
    "  def __init__(self, protein_family):\n",
    "    self.protein_family = protein_family\n",
    "    self.msa_file = '/content/drive/MyDrive/PhD/Pfam/'+ f\"{self.pfam}_seed_hmmalign_no_inserts.fasta\"\n",
    "\n",
    "  def shuffle_col(self,column):\n",
    "\n",
    "    if len(set(column)) == 1:\n",
    "        return column\n",
    "\n",
    "    aa_list = list(column)\n",
    "    random.shuffle(aa_list)\n",
    "\n",
    "    return ''.join(aa_list)\n",
    "\n",
    "  def mix_fasta_column(self):\n",
    "    mix_column = '/content/drive/MyDrive/PhD/Pfam/' + f\"{self.pfam}_mix_column.fasta\"\n",
    "\n",
    "    records = list(SeqIO.parse(self.msa_file, \"fasta\"))\n",
    "    seq_length = len(records[0].seq)\n",
    "    shuffled_records = []\n",
    "\n",
    "    for i in range(seq_length):\n",
    "        column = ''.join(record.seq[i] for record in records)\n",
    "        shuffled_column = self.shuffle_col(column)\n",
    "        for j, record in enumerate(records):\n",
    "            if j >= len(shuffled_records):\n",
    "                shuffled_records.append(record)\n",
    "            shuffled_records[j].seq = shuffled_records[j].seq[:i] + shuffled_column[j] + shuffled_records[j].seq[i+1:]\n",
    "\n",
    "    shuffled_msa = [record for record in shuffled_records]\n",
    "    SeqIO.write(shuffled_msa, mix_column, \"fasta\")\n",
    "\n",
    "    print('Generate Mix columns data!')\n",
    "\n",
    "  def shuffle_fasta_all(self):\n",
    "    shuffle_all = '/content/drive/MyDrive/PhD/Pfam/' + f\"{self.pfam}_shuffle_all.fasta\"\n",
    "    shuffle_order = '/content/drive/MyDrive/PhD/Pfam/' + f\"{self.pfam}_shuffle_all_order.txt\"\n",
    "\n",
    "    with open(self.msa_file, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    sequences = []\n",
    "    current_sequence = ''\n",
    "    for line in lines:\n",
    "        line = line.rstrip()\n",
    "        if line.startswith('>'):\n",
    "            if current_sequence:\n",
    "                sequences.append(current_sequence)\n",
    "            sequences.append(line)\n",
    "            current_sequence = ''\n",
    "        else:\n",
    "            current_sequence += line\n",
    "    sequences.append(current_sequence)\n",
    "    sequence_length = len(sequences[1])\n",
    "\n",
    "    shuffled_sequences = []\n",
    "    shuffled_order = []\n",
    "\n",
    "    for sequence in sequences:\n",
    "        if not sequence.startswith('>'):\n",
    "            # for each sequence, regenerate new sequences in a random order using the same amino acid composition\n",
    "            shuffled_indices = random.sample(range(len(sequence)), len(sequence))\n",
    "            shuffled_order.append(shuffled_indices)\n",
    "            shuffled_sequence = ''.join(''.join([sequence[i] for i in shuffled_indices]))\n",
    "            shuffled_sequences.append(shuffled_sequence)\n",
    "        else:\n",
    "            shuffled_sequences.append(sequence)\n",
    "\n",
    "    with open(shuffle_all, 'w') as file:\n",
    "        file.write('\\n'.join(shuffled_sequences))\n",
    "\n",
    "    with open(shuffle_order,'w') as file:\n",
    "      write = csv.writer(file)\n",
    "      write.writerows(shuffled_order)\n",
    "\n",
    "    print('Generate Shuffle all data!')\n",
    "\n",
    "\n",
    "  def shuffle_fasta_column(self):\n",
    "    shuffle_column = '/content/drive/MyDrive/PhD/Pfam/' + f\"{self.pfam}_shuffle_column.fasta\"\n",
    "    shuffle_order = '/content/drive/MyDrive/PhD/Pfam/' + f\"{self.pfam}_shuffle_column_order.txt\"\n",
    "\n",
    "    with open(self.msa_file, 'r') as file:\n",
    "      lines = file.readlines()\n",
    "\n",
    "    sequences = []\n",
    "    current_sequence = ''\n",
    "    for line in lines:\n",
    "      line = line.rstrip()\n",
    "      if line.startswith('>'):\n",
    "        if current_sequence:\n",
    "          sequences.append(current_sequence)\n",
    "        sequences.append(line)\n",
    "        current_sequence = ''\n",
    "      else:\n",
    "        current_sequence += line\n",
    "    sequences.append(current_sequence)\n",
    "    sequence_length = len(sequences[1])\n",
    "\n",
    "    shuffled_sequences = []\n",
    "    shuffled_order = []\n",
    "    # regernate new sequences using the same order\n",
    "    shuffled_indices = random.sample(range(sequence_length), sequence_length)\n",
    "    shuffled_order.append(shuffled_indices)\n",
    "\n",
    "    for sequence in sequences:\n",
    "      if not sequence.startswith('>'):\n",
    "        shuffled_sequence = ''.join(''.join([sequence[i] for i in shuffled_indices]))\n",
    "        shuffled_sequences.append(shuffled_sequence)\n",
    "      else:\n",
    "        shuffled_sequences.append(sequence)\n",
    "\n",
    "    with open(shuffle_column, 'w') as file:\n",
    "      file.write('\\n'.join(shuffled_sequences))\n",
    "\n",
    "    with open(shuffle_order,'w') as file:\n",
    "      write = csv.writer(file)\n",
    "      write.writerows(shuffled_order)\n",
    "\n",
    "    print('Generate Shuffle columns data!')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "59c6d25b8e8cb90d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def remove_insertions(sequence):\n",
    "  deletekeys = dict.fromkeys(string.ascii_lowercase)\n",
    "  deletekeys[\".\"] = None\n",
    "  deletekeys[\"*\"] = None\n",
    "  translation = str.maketrans(deletekeys)\n",
    "  \"\"\" Removes any insertions into the sequence. Needed to load aligned sequences in an MSA. \"\"\"\n",
    "  return sequence.translate(translation)\n",
    "\n",
    "\n",
    "class Extractor:\n",
    "\n",
    "  def __init__(self, protein_family, msa_type):\n",
    "    self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    self.model_name = \"esm_msa1b_t12_100M_UR50S\"\n",
    "    self.encoding_dim, self.encoding_layer, self.max_seq_length = 768, 12, 1022\n",
    "    self.protein_family = protein_family\n",
    "    self.msa_type = msa_type\n",
    "    self.emb_path = './embeddings/'\n",
    "    self.attn_path = '/attentions/'\n",
    "   \n",
    "    if self.msa_type == \"no\":\n",
    "      self.msa_fasta_file = '/MSA/' + f\"{self.protein_family}_seed_hmmalign_no_inserts.fasta\"\n",
    "    # Shuffle column data\n",
    "    elif self.msa_type == \"sc\":\n",
    "      self.msa_fasta_file = '/MSA/' + f\"{self.protein_family}_shuffle_column.fasta\"\n",
    "    # Shuffle all data\n",
    "    elif self.msa_type == \"sa\":\n",
    "      self.msa_fasta_file = '/MSA/' + f\"{self.protein_family}_shuffle_all.fasta\"\n",
    "    # Mix column data\n",
    "    else:\n",
    "      self.msa_fasta_file = '/MSA/' + f\"{self.protein_family}_mix_column.fasta\"\n",
    "\n",
    "  def read_msa(self):\n",
    "    return [(record.description, remove_insertions(str(record.seq)))\n",
    "            for record in SeqIO.parse(self.msa_fasta_file, \"fasta\")]\n",
    "\n",
    "  def get_col_attention(self):\n",
    "    model, alphabet = pretrained.load_model_and_alphabet(self.model_name)\n",
    "    batch_converter = alphabet.get_batch_converter()\n",
    "    tokens_to_index = alphabet.tok_to_idx.copy()\n",
    "\n",
    "    if self.msa_type == \"no\":\n",
    "      col_attn = self.attn_path + self.protein_family + '_attn_no_shuffle_' + self.model_name + '.pt'\n",
    "    # Shuffle column data\n",
    "    elif self.msa_type == \"sc\":\n",
    "      col_attn = self.attn_path + self.protein_family + '_attn_shuffle_column_' + self.model_name + '.pt'\n",
    "    # Shuffle all data\n",
    "    elif self.msa_type == \"sa\":\n",
    "      col_attn = self.attn_path + self.protein_family + '_attn_shuffle_all_' + self.model_name + '.pt'\n",
    "    # Mix column data\n",
    "    else:\n",
    "      col_attn = self.attn_path + self.protein_family + '_attn_mix_column_' + self.model_name + '.pt'\n",
    "\n",
    "    model.eval()\n",
    "    # process fasta file into pytorch dataset\n",
    "    msa_data = [self.read_msa()]\n",
    "    msa_labels, msa_strs, msa_tokens = batch_converter(msa_data)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        results = model(msa_tokens, repr_layers=[12], need_head_weights=False)\n",
    "\n",
    "    torch.save(results, col_attn)\n",
    "    print(\"Embeddings saved in output file:\", col_attn)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f032996cc3252c6f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
