{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Deciphering the Black Box: Mastering the MSA Transformer for Phylogenetic Tree Construction"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "159965dd8885eca0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Install and import package ##"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ff6b7b4fa8508565"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-09-23T01:21:29.648451Z",
     "start_time": "2023-09-23T01:21:20.587042Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Bio in /Users/cassie/opt/anaconda3/envs/deeplearning/lib/python3.8/site-packages (1.5.9)\r\n",
      "Requirement already satisfied: mygene in /Users/cassie/opt/anaconda3/envs/deeplearning/lib/python3.8/site-packages (from Bio) (3.2.2)\r\n",
      "Requirement already satisfied: gprofiler-official in /Users/cassie/opt/anaconda3/envs/deeplearning/lib/python3.8/site-packages (from Bio) (1.0.0)\r\n",
      "Requirement already satisfied: pooch in /Users/cassie/opt/anaconda3/envs/deeplearning/lib/python3.8/site-packages (from Bio) (1.7.0)\r\n",
      "Requirement already satisfied: requests in /Users/cassie/opt/anaconda3/envs/deeplearning/lib/python3.8/site-packages (from Bio) (2.28.1)\r\n",
      "Requirement already satisfied: tqdm in /Users/cassie/opt/anaconda3/envs/deeplearning/lib/python3.8/site-packages (from Bio) (4.65.0)\r\n",
      "Requirement already satisfied: pandas in /Users/cassie/opt/anaconda3/envs/deeplearning/lib/python3.8/site-packages (from Bio) (1.5.2)\r\n",
      "Requirement already satisfied: biopython>=1.80 in /Users/cassie/opt/anaconda3/envs/deeplearning/lib/python3.8/site-packages (from Bio) (1.81)\r\n",
      "Requirement already satisfied: numpy in /Users/cassie/opt/anaconda3/envs/deeplearning/lib/python3.8/site-packages (from biopython>=1.80->Bio) (1.23.5)\r\n",
      "Requirement already satisfied: biothings-client>=0.2.6 in /Users/cassie/opt/anaconda3/envs/deeplearning/lib/python3.8/site-packages (from mygene->Bio) (0.3.0)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Users/cassie/opt/anaconda3/envs/deeplearning/lib/python3.8/site-packages (from pandas->Bio) (2.8.2)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/cassie/opt/anaconda3/envs/deeplearning/lib/python3.8/site-packages (from pandas->Bio) (2022.7)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/cassie/opt/anaconda3/envs/deeplearning/lib/python3.8/site-packages (from pooch->Bio) (22.0)\r\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /Users/cassie/opt/anaconda3/envs/deeplearning/lib/python3.8/site-packages (from pooch->Bio) (2.5.2)\r\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/cassie/opt/anaconda3/envs/deeplearning/lib/python3.8/site-packages (from requests->Bio) (2.0.4)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/cassie/opt/anaconda3/envs/deeplearning/lib/python3.8/site-packages (from requests->Bio) (3.4)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/cassie/opt/anaconda3/envs/deeplearning/lib/python3.8/site-packages (from requests->Bio) (1.26.14)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/cassie/opt/anaconda3/envs/deeplearning/lib/python3.8/site-packages (from requests->Bio) (2023.5.7)\r\n",
      "Requirement already satisfied: six>=1.5 in /Users/cassie/opt/anaconda3/envs/deeplearning/lib/python3.8/site-packages (from python-dateutil>=2.8.1->pandas->Bio) (1.16.0)\r\n",
      "Requirement already satisfied: ete3 in /Users/cassie/opt/anaconda3/envs/deeplearning/lib/python3.8/site-packages (3.1.2)\r\n",
      "Collecting dendropy\r\n",
      "  Using cached DendroPy-4.6.1-py3-none-any.whl (458 kB)\r\n",
      "Requirement already satisfied: setuptools in /Users/cassie/opt/anaconda3/envs/deeplearning/lib/python3.8/site-packages (from dendropy) (65.6.3)\r\n",
      "Installing collected packages: dendropy\r\n",
      "Successfully installed dendropy-4.6.1\r\n"
     ]
    }
   ],
   "source": [
    "!pip install fair-esm --quiet\n",
    "!pip install transformers --quiet\n",
    "!pip install pysam --quiet\n",
    "!pip install Bio\n",
    "!pip install ete3\n",
    "!pip install dendropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import random\n",
    "import string\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "from Bio import SeqIO\n",
    "from ete3 import Tree\n",
    "from esm import Alphabet, FastaBatchedDataset, ProteinBertModel, MSATransformer, pretrained\n",
    "from pysam import FastaFile, FastxFile\n",
    "from scipy import stats\n",
    "from torch.utils.data import TensorDataset, Dataset"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-23T01:21:33.690095Z",
     "start_time": "2023-09-23T01:21:33.676039Z"
    }
   },
   "id": "f1abb88b67515501"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Generate 4 kinds of MSA ##"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "507509b4bad5f3c"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "EMB_PATH = './Embeddings/'\n",
    "ATTN_PATH = './Attentions/'\n",
    "MSA_PATH = './Msa/'\n",
    "TREE_PATH = './Trees/'\n",
    "\n",
    "MSA_TYPE_MAP = {\n",
    "        \"no\": \"_seed_hmmalign_no_inserts.fasta\",\n",
    "        \"sc\": \"_shuffle_column.fasta\",\n",
    "        \"sa\": \"_shuffle_all.fasta\",\n",
    "        \"default\": \"_mix_column.fasta\"\n",
    "    }\n",
    "\n",
    "EMB_TYPE_MAP = {\n",
    "        \"no\": \"_emb_no_shuffle_\",\n",
    "        \"sc\": \"_emb_shuffle_column_\",\n",
    "        \"sa\": \"_emb_shuffle_all_\",\n",
    "        \"default\": \"_emb_mix_column_\"\n",
    "    }\n",
    "    \n",
    "ATTN_TYPE_MAP = {\n",
    "        \"no\": \"_attn_no_shuffle_\",\n",
    "        \"sc\": \"_attn_shuffle_column_\",\n",
    "        \"sa\": \"_attn_shuffle_all_\",\n",
    "        \"default\": \"_attn_mix_column_\"\n",
    "    }"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-23T05:02:58.520983Z",
     "start_time": "2023-09-23T05:02:58.518579Z"
    }
   },
   "id": "9f924d6ff422fea5"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "class ChangeAA:\n",
    "\n",
    "    def __init__(self, protein_family):\n",
    "        self.protein_family = protein_family\n",
    "        self.msa_file = f'{MSA_PATH}{self.protein_family}_seed_hmmalign_no_inserts.fasta'\n",
    "\n",
    "    def _shuffle_list(self, data_list):\n",
    "        if len(set(data_list)) == 1:\n",
    "            return data_list\n",
    "        random.shuffle(data_list)\n",
    "        return data_list\n",
    "\n",
    "    def mix_fasta_column(self):\n",
    "        output_file = f'{MSA_PATH}{self.protein_family}_mix_column.fasta'\n",
    "        records = list(SeqIO.parse(self.msa_file, \"fasta\"))\n",
    "        seq_length = len(records[0].seq)\n",
    "        shuffled_records = []\n",
    "\n",
    "        for i in range(seq_length):\n",
    "            column = ''.join(record.seq[i] for record in records)\n",
    "            shuffled_column = self._shuffle_list(list(column))\n",
    "            for j, record in enumerate(records):\n",
    "                if j >= len(shuffled_records):\n",
    "                    shuffled_records.append(record)\n",
    "                shuffled_records[j].seq = shuffled_records[j].seq[:i] + shuffled_column[j] + shuffled_records[j].seq[i+1:]\n",
    "\n",
    "        SeqIO.write(shuffled_records, output_file, \"fasta\")\n",
    "        print('Generated Mix columns data!')\n",
    "\n",
    "    def _read_fasta(self):\n",
    "        with open(self.msa_file, 'r') as file:\n",
    "            lines = file.readlines()\n",
    "\n",
    "        sequences = []\n",
    "        current_sequence = ''\n",
    "        for line in lines:\n",
    "            line = line.rstrip()\n",
    "            if line.startswith('>'):\n",
    "                if current_sequence:\n",
    "                    sequences.append(current_sequence)\n",
    "                sequences.append(line)\n",
    "                current_sequence = ''\n",
    "            else:\n",
    "                current_sequence += line\n",
    "        sequences.append(current_sequence)\n",
    "\n",
    "        return sequences\n",
    "\n",
    "    def shuffle_fasta_all(self):\n",
    "        output_seq_file = f'{MSA_PATH}{self.protein_family}_shuffle_all.fasta'\n",
    "        output_order_file = f'{MSA_PATH}{self.protein_family}_shuffle_all_order.txt'\n",
    "        sequences = self._read_fasta()\n",
    "        sequence_length = len(sequences[1])\n",
    "\n",
    "        shuffled_sequences = []\n",
    "        shuffled_order = []\n",
    "\n",
    "        for sequence in sequences:\n",
    "            if not sequence.startswith('>'):\n",
    "                shuffled_indices = random.sample(range(sequence_length), sequence_length)\n",
    "                shuffled_order.append(shuffled_indices)\n",
    "                shuffled_sequence = ''.join(sequence[i] for i in shuffled_indices)\n",
    "                shuffled_sequences.append(shuffled_sequence)\n",
    "            else:\n",
    "                shuffled_sequences.append(sequence)\n",
    "\n",
    "        with open(output_seq_file, 'w') as file:\n",
    "            file.write('\\n'.join(shuffled_sequences))\n",
    "\n",
    "        with open(output_order_file, 'w') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerows(shuffled_order)\n",
    "\n",
    "        print('Generated Shuffle all data!')\n",
    "\n",
    "    def shuffle_fasta_column(self):\n",
    "        output_seq_file = f'{MSA_PATH}{self.protein_family}_shuffle_column.fasta'\n",
    "        output_order_file = f'{MSA_PATH}{self.protein_family}_shuffle_column_order.txt'\n",
    "        sequences = self._read_fasta()\n",
    "        sequence_length = len(sequences[1])\n",
    "\n",
    "        shuffled_order = [random.sample(range(sequence_length), sequence_length)]\n",
    "        shuffled_sequences = []\n",
    "\n",
    "        for sequence in sequences:\n",
    "            if not sequence.startswith('>'):\n",
    "                shuffled_sequence = ''.join(sequence[i] for i in shuffled_order[0])\n",
    "                shuffled_sequences.append(shuffled_sequence)\n",
    "            else:\n",
    "                shuffled_sequences.append(sequence)\n",
    "\n",
    "        with open(output_seq_file, 'w') as file:\n",
    "            file.write('\\n'.join(shuffled_sequences))\n",
    "\n",
    "        with open(output_order_file, 'w') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerows(shuffled_order)\n",
    "\n",
    "        print('Generated Shuffle columns data!')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-23T04:56:53.590224Z",
     "start_time": "2023-09-23T04:56:53.588408Z"
    }
   },
   "id": "59c6d25b8e8cb90d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Generate four kinds of embeddings and attentions"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8043fea857aab504"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def remove_insertions(sequence):\n",
    "  deletekeys = dict.fromkeys(string.ascii_lowercase)\n",
    "  deletekeys[\".\"] = None\n",
    "  deletekeys[\"*\"] = None\n",
    "  translation = str.maketrans(deletekeys)\n",
    "  \"\"\" Removes any insertions into the sequence. Needed to load aligned sequences in an MSA. \"\"\"\n",
    "  return sequence.translate(translation)\n",
    "\n",
    "class Extractor:\n",
    "\n",
    "    def __init__(self, protein_family, msa_type):\n",
    "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        self.model_name = \"esm_msa1b_t12_100M_UR50S\"\n",
    "        self.encoding_dim, self.encoding_layer, self.max_seq_length = 768, 12, 1022\n",
    "        self.protein_family = protein_family\n",
    "        self.msa_type = msa_type if msa_type in MSA_TYPE_MAP else \"default\"\n",
    "        self.msa_fasta_file = f'{MSA_PATH}{protein_family}{MSA_TYPE_MAP[self.msa_type]}'\n",
    "\n",
    "    def read_msa(self):\n",
    "        return [(record.description, remove_insertions(str(record.seq)))\n",
    "                for record in SeqIO.parse(self.msa_fasta_file, \"fasta\")]\n",
    "\n",
    "    def get_embedding(self):\n",
    "        model, alphabet = pretrained.load_model_and_alphabet(self.model_name)\n",
    "        batch_converter = alphabet.get_batch_converter()\n",
    "\n",
    "        emb = f'{EMB_PATH}{self.protein_family}{EMB_TYPE_MAP[self.msa_type]}{self.model_name}.pt'\n",
    "        plm_embedding = {}\n",
    "\n",
    "        model.eval()\n",
    "        msa_data = [self.read_msa()]\n",
    "        msa_labels, msa_strs, msa_tokens = batch_converter(msa_data)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for layer in range(self.encoding_layer):\n",
    "                out = model(msa_tokens, repr_layers=[layer], return_contacts = False)\n",
    "                token_representations = out[\"representations\"][layer].view(-1, self.sequence_length+1, self.encoding_dim)\n",
    "                # remove the start token\n",
    "                token_representations = token_representations[:,1:,:]\n",
    "                print(f\"Finish extracting embeddings from layer {layer}.\")\n",
    "                plm_embedding[layer] = token_representations\n",
    "\n",
    "        torch.save(plm_embedding, emb)\n",
    "        print(\"Embeddings saved in output file:\",emb)\n",
    "\n",
    "    \n",
    "    def get_col_attention(self):\n",
    "        model, alphabet = pretrained.load_model_and_alphabet(self.model_name)\n",
    "        batch_converter = alphabet.get_batch_converter()\n",
    "\n",
    "        attn = f'{ATTN_PATH}{self.protein_family}{ATTN_TYPE_MAP[self.msa_type]}{self.model_name}.pt'\n",
    "\n",
    "        model.eval()\n",
    "        msa_data = [self.read_msa()]\n",
    "        msa_labels, msa_strs, msa_tokens = batch_converter(msa_data)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            results = model(msa_tokens, repr_layers=[12], need_head_weights=True)\n",
    "\n",
    "        torch.save(results, attn)\n",
    "        print(\"Column attention saved in output file:\", attn)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-23T04:56:57.098066Z",
     "start_time": "2023-09-23T04:56:57.087733Z"
    }
   },
   "id": "f032996cc3252c6f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.Calculate evolutionary distances for each protein domain ##"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "74845a3062e55879"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "LAYER = 12\n",
    "HEAD = 12\n",
    "\n",
    "class EvDist:\n",
    "    \n",
    "    \"\"\"Class for evolutionary distance processing\"\"\"\n",
    "\n",
    "    def __init__(self, protein_family, msa_type):\n",
    "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        self.model_name = \"esm_msa1b_t12_100M_UR50S\"\n",
    "        self.protein_family = protein_family\n",
    "        self.msa_type = msa_type if msa_type in MSA_TYPE_MAP else \"default\"\n",
    "        self.msa_fasta_file = f'{MSA_PATH}{protein_family}{MSA_TYPE_MAP[self.msa_type]}'\n",
    "        self.emb = f'{EMB_PATH}{self.protein_family}{EMB_TYPE_MAP[self.msa_type]}{self.model_name}.pt'\n",
    "        self.attn = f'{ATTN_PATH}{self.protein_family}{ATTN_TYPE_MAP[self.msa_type]}{self.model_name}.pt'\n",
    "        self.tree = os.path.join('/content/drive/MyDrive/PhD/tree', f\"{self.protein_family}.tree\")\n",
    "\n",
    "    @staticmethod\n",
    "    def euc_distance(a, b):\n",
    "        \"\"\"Calculate Euclidean distance between two points.\"\"\"\n",
    "        return np.sqrt(np.sum((a - b)**2))\n",
    "\n",
    "    def evolutionary_distance(self, phylo_tree, seq_labels):\n",
    "        \"\"\"Calculate the evolutionary distance between sequences based on the phylogenetic tree.\"\"\"\n",
    "        phylo_tree = Tree(self.tree)\n",
    "        ev_distances = []\n",
    "\n",
    "        for ref_seq_name in seq_labels:\n",
    "            ref_seq_node = phylo_tree & ref_seq_name\n",
    "\n",
    "            current_seq_distances = []\n",
    "            for ex_seq_name in seq_labels:\n",
    "                ex_seq_node = phylo_tree & ex_seq_name\n",
    "                distance = ref_seq_node.get_distance(ex_seq_node)\n",
    "                current_seq_distances.append(distance)\n",
    "\n",
    "            ev_distances.append(current_seq_distances)\n",
    "\n",
    "        return np.array(ev_distances)\n",
    "\n",
    "    def pairwise_euclidean_distance(self, emb):\n",
    "        emb = np.array(emb)\n",
    "        m, n, p = emb.shape\n",
    "\n",
    "        distances = np.zeros((m, m))\n",
    "\n",
    "        for i in range(m):\n",
    "            for j in range(i+1, m):\n",
    "                distance = self.euc_distance(emb[i].flatten(), emb[j].flatten())\n",
    "                distances[i, j] = distance\n",
    "                distances[j, i] = distance\n",
    "\n",
    "        return distances\n",
    "\n",
    "    def compute_embedding_correlation(self):\n",
    "        \"\"\"\n",
    "        Calculate the correlation between evolutionary distances from the trees and pairwise Euclidean distances of embeddings\n",
    "        \"\"\"\n",
    "        output_file = os.path.join('./Results', f\"{self.protein_family}_ev_and_euclidean_analysis.csv\")\n",
    "        \n",
    "        # Load embeddings\n",
    "        embeddings = torch.load(self.emb)\n",
    "        \n",
    "        # Load sequence names and extract shorter names\n",
    "        sequences = [record.id for record in SeqIO.parse(self.msa_fasta_file, \"fasta\")]\n",
    "        sequence_list = [seq.split(' ')[0] for seq in sequences]\n",
    "\n",
    "        # Compute evolutionary distances\n",
    "        ev_distances = self.evolutionary_distance(Tree(self.tree), sequence_list)\n",
    "        correlations = []\n",
    "\n",
    "        # Compute Euclidean distances and their correlation with evolutionary distances\n",
    "        for layer in range(LAYER):\n",
    "            euc_distances = self.pairwise_euclidean_distance(embeddings[layer].mean(1))\n",
    "            spear_corr = stats.spearmanr(ev_distances.flatten(), euc_distances.flatten())\n",
    "            correlations.append([self.protein_family, layer, spear_corr.correlation, spear_corr.pvalue])\n",
    "\n",
    "        # Save to CSV file\n",
    "        with open(output_file, 'w') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow(['Protein family', 'Layer', 'Correlation', 'P value'])\n",
    "            writer.writerows(correlations)\n",
    "            \n",
    "    def compute_attention_correlation(self):\n",
    "        \"\"\"\n",
    "        Calculate the correlation between evolutionary distances from the trees and column attention\n",
    "        \"\"\"\n",
    "        output_file = os.path.join('./Results', f\"{self.protein_family}_ev_and_euclidean_analysis.csv\")\n",
    "        \n",
    "        # Load sequence names and extract shorter names\n",
    "        sequences = [record.id for record in SeqIO.parse(self.msa_fasta_file, \"fasta\")]\n",
    "        sequence_list = [seq.split(' ')[0] for seq in sequences]\n",
    "        # Compute evolutionary distances\n",
    "        ev_distances = self.evolutionary_distance(Tree(self.tree), sequence_list)\n",
    "        \n",
    "        # Load column attention\n",
    "        attn = torch.load(self.attn)\n",
    "        # remove start token\n",
    "        attn_mean_on_cols_symm = attn[\"col_attentions\"].cpu().numpy()[0,:,:,1:,:,:].mean(axis=2)\n",
    "        attn_mean_on_cols_symm += attn_mean_on_cols_symm.transpose(0, 1, 3, 2)\n",
    "        # Generate the row and column indices of the upper triangular part of the attention matrix\n",
    "        tri_indices = np.triu_indices(attn_mean_on_cols_symm.shape[-1])\n",
    "        # Select the upper triangle of attention and distance matrix\n",
    "        attn = attn_mean_on_cols_symm[..., tri_indices[0], tri_indices[1]]  # (12,12, M * (M+1) / 2)\n",
    "        ev = ev_distances[tri_indices]\n",
    "        # Reshape the attention matrix\n",
    "        attn = attn.transpose(2, 0, 1).reshape(-1, 12 * 12)\n",
    "        df_attn = pd.DataFrame(attn,columns=[f\"lyr{i}_hd{j}\" for i in range(12) for j in range(12)])\n",
    "\n",
    "        for layer in range(12):\n",
    "            for head in range(12):\n",
    "                attns = df_attn[f\"lyr{layer}_hd{head}\"].values\n",
    "                sp_corr = stats.spearmanr(ev, attns)\n",
    "                spear_evdist_corr.append([self.pfam, layer, head, sp_corr.correlation, sp_corr.pvalue])\n",
    "        # field names\n",
    "        fields = ['Pfam id', 'Layer', 'Head', 'Correlation','Pvalue']\n",
    "        # save csv file\n",
    "        with open(self.output_corr_data_file, 'w') as f:\n",
    "        # using csv.writer method from CSV package\n",
    "            write = csv.writer(f)\n",
    "            write.writerow(fields)\n",
    "            write.writerows(spear_evdist_corr)\n",
    "        "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-23T04:57:00.054412Z",
     "start_time": "2023-09-23T04:57:00.049370Z"
    }
   },
   "id": "c4b1c117653a53cc"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "63678f3b533734b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
